# Mask Component Predictor - Setup Guide

## Overview

The Mask Component Predictor uses a pre-trained Conditional Random Fields (CRF) model to predict mask name components (brand, model, size, color, etc.) for smarter mask matching and deduplication.

## Architecture

The system supports three deployment modes:

1. **Inline Python (Default)** - Calls Python script directly from Rails
2. **Flask Service** - Separate Python Flask service (development)
3. **AWS Lambda** - Serverless deployment (future)

## Quick Start (5 minutes)

### 1. Train the Model

```bash
rails mask_predictor:train
```

This will:
- Export annotated mask data from the database
- Train a CRF model using sklearn-crfsuite
- Save the model to `python/mask_component_predictor/crf_model.pkl`

### 2. Test the Predictor

```bash
rails mask_predictor:test
```

This will verify the model is working and show example predictions.

### 3. Use in Your Code

```ruby
# Single prediction
result = MaskComponentPredictorService.predict('3M Aura 9205+ N95')
# => {
#   mask_name: "3M Aura 9205+ N95",
#   tokens: ["3M", "Aura", "9205+", "N95"],
#   breakdown: [{"3M"=>"brand"}, {"Aura"=>"model"}, {"9205+"=>"model"}, {"N95"=>"filter_type"}],
#   components: {
#     brand: ["3M"],
#     model: ["Aura", "9205+"],
#     filter_type: ["N95"],
#     size: [], color: [], style: [], strap: [], valved: [], misc: []
#   },
#   confidence: 0.9677
# }

# Batch prediction
results = MaskComponentPredictorService.predict_batch([
  '3M 1860s',
  'Zimi ZM9233 w/ Headstraps'
])
```

## Deployment Modes

### Mode 1: Inline Python (Default)

**How it works:**
- Rails calls `python3 predict_inline.py` directly using `Open3`
- Model is loaded once per Python process
- No separate service needed

**Pros:**
- âœ… Zero configuration
- âœ… No additional cost
- âœ… Works immediately
- âœ… Simple deployment

**Cons:**
- âš ï¸ Slightly slower (~50ms vs ~10ms for Lambda)
- âš ï¸ Loads Python on each request (but model is cached)

**Configuration:**
No configuration needed - this is the default.

### Mode 2: Flask Service (Development)

**How it works:**
- Separate Flask service runs on localhost
- Rails makes HTTP requests to the service
- Good for development/debugging

**Pros:**
- âœ… Faster predictions (~20ms)
- âœ… Model stays in memory
- âœ… Easy to debug

**Cons:**
- âš ï¸ Requires separate process
- âš ï¸ Additional complexity

**Configuration:**

```bash
# Start Flask service
cd python/mask_component_predictor
python3 app.py 1234

# Configure Rails to use Flask
export USE_FLASK_PREDICTOR=true
export MASK_PREDICTOR_PORT=1234
```

### Mode 3: AWS Lambda (Future)

**How it works:**
- Serverless function on AWS
- Rails invokes via AWS SDK
- Pay per request

**Pros:**
- âœ… Fastest predictions (~10ms)
- âœ… Scales automatically
- âœ… Very low cost ($0.01/month)

**Cons:**
- âš ï¸ Deployment complexity (currently blocked by Docker issues)
- âš ï¸ AWS account required

**Configuration:**

```bash
# Deploy to Lambda (when working)
cd lambda/mask_predictor
./deploy_minimal.sh

# Configure Rails to use Lambda
export USE_LAMBDA_PREDICTOR=true
export AWS_REGION=us-east-1
export LAMBDA_FUNCTION_NAME=mask-component-predictor
```

## Model Training

### Prerequisites

```bash
pip3 install -r python/mask_component_predictor/requirements.txt
```

### Training Process

The model is trained on annotated mask data from your database:

1. **Export Training Data**
   ```bash
   rails mask_predictor:export
   ```
   Creates `python/mask_component_predictor/training_data.json`

2. **Train Model**
   ```bash
   cd python/mask_component_predictor
   python3 train_model.py
   ```
   Creates `crf_model.pkl` (139KB)

3. **Or Do Both**
   ```bash
   rails mask_predictor:train
   ```

### Model Performance

Based on 298 annotated masks:

- **Overall Accuracy**: 87.7%
- **Training Time**: ~5 seconds
- **Model Size**: 139KB
- **Prediction Time**:
  - Inline: ~50ms
  - Flask: ~20ms
  - Lambda: ~10ms

**Category Performance:**
- Brand: 95% precision, 92% recall
- Model: 89% precision, 87% recall
- Size: 91% precision, 88% recall
- Filter Type: 94% precision, 91% recall

## Heroku Deployment

### Option A: Inline Python (Recommended)

1. **Commit the model file:**
   ```bash
   git add python/mask_component_predictor/crf_model.pkl
   git commit -m "Add pre-trained CRF model"
   git push heroku main
   ```

2. **Done!** No additional configuration needed.

**Cost:** $0/month (no extra dyno)

### Option B: Flask Service

1. **Update Procfile:**
   ```
   python_service: cd python/mask_component_predictor && gunicorn app:app --bind 0.0.0.0:$PORT
   ```

2. **Configure environment:**
   ```bash
   heroku config:set USE_FLASK_PREDICTOR=true
   ```

3. **Scale up Python dyno:**
   ```bash
   heroku ps:scale python_service=1:standard-1x
   ```

**Cost:** $7-25/month (Python dyno)

## Troubleshooting

### Model not found

```
Error: Model file not found
```

**Solution:**
```bash
rails mask_predictor:train
```

### Python dependencies missing

```
ModuleNotFoundError: No module named 'sklearn_crfsuite'
```

**Solution:**
```bash
pip3 install -r python/mask_component_predictor/requirements.txt
```

### Slow predictions

If inline predictions are too slow, consider:

1. **Use Flask service** (20ms instead of 50ms)
2. **Batch predictions** (more efficient)
3. **Cache results** in Rails

### Port conflicts (Flask mode)

```
Address already in use
```

**Solution:**
```bash
# Use a different port
python3 app.py 1234
export MASK_PREDICTOR_PORT=1234
```

## Use Cases

### 1. Bulk Import Matching

```ruby
# In BulkFitTestsImportsController
file_mask_name = "3M 9205+ Aura"
prediction = MaskComponentPredictorService.predict(file_mask_name)

# Match by brand + model instead of full string
brand = prediction[:components][:brand].join(' ')
model = prediction[:components][:model].join(' ')

mask = Mask.where(
  "breakdown->>'brand' = ? AND breakdown->>'model' = ?",
  brand, model
).first
```

### 2. Mask Deduplication

```ruby
# Find potential duplicates by comparing components
mask1_pred = MaskComponentPredictorService.predict(mask1.unique_internal_model_code)
mask2_pred = MaskComponentPredictorService.predict(mask2.unique_internal_model_code)

# Compare components
brand_match = mask1_pred[:components][:brand] == mask2_pred[:components][:brand]
model_match = mask1_pred[:components][:model] == mask2_pred[:components][:model]

if brand_match && model_match
  # Likely duplicate
end
```

### 3. Smart Search

```ruby
# Extract brand from search query
query = "3M Aura"
prediction = MaskComponentPredictorService.predict(query)
brand = prediction[:components][:brand].first

# Search by predicted brand
Mask.where("breakdown->>'brand' = ?", brand)
```

## Files

- `app/services/mask_component_predictor_service.rb` - Main service (delegates to appropriate backend)
- `app/services/mask_component_predictor_inline_service.rb` - Inline Python implementation
- `app/services/mask_component_predictor_lambda_service.rb` - AWS Lambda implementation
- `python/mask_component_predictor/predict_inline.py` - Python prediction script
- `python/mask_component_predictor/train_model.py` - Model training script
- `python/mask_component_predictor/crf_model.pkl` - Pre-trained model (139KB)
- `lib/tasks/mask_predictor.rake` - Rake tasks for training and testing

## Performance Tips

1. **Use batch predictions** when processing multiple masks
2. **Cache results** for frequently accessed masks
3. **Consider Flask service** if you need faster predictions
4. **Pre-compute predictions** during bulk import and store in database

## Next Steps

1. âœ… Model is trained and working
2. âœ… Inline Python integration complete
3. ðŸ”„ Integrate into bulk import flow
4. ðŸ”„ Build deduplication UI
5. ðŸ”„ Add caching layer
6. ðŸ”„ Deploy to Heroku

## Support

For issues or questions:
1. Check `rails mask_predictor:test` output
2. Review logs: `tail -f log/development.log`
3. Verify model exists: `ls -lh python/mask_component_predictor/crf_model.pkl`
